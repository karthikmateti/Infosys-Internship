{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1WaC30BG_Sv",
        "outputId": "ac9ec9ce-e619-4f68-cfc2-b17cd0bde47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'srt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'srt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Upgrade pip and install ffmpeg\n",
        "!pip install --upgrade pip\n",
        "!apt-get install ffmpeg -y\n",
        "\n",
        "# Install torch and Whisper\n",
        "!pip install torch --quiet\n",
        "!pip install git+https://github.com/openai/whisper.git --quiet\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install vosk streamlit pyngrok jiwer soundfile groq --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import whisper\n",
        "import soundfile as sf\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from groq import Groq\n",
        "from jiwer import wer\n",
        "import json\n"
      ],
      "metadata": {
        "id": "_r9wpkHcHOv2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your Groq API key here\n",
        "# Replace \"gsk_your_actual_api_key_here\" with your actual key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "OXvy_WUDLOPa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"meeting_pipeline\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "11SRsJTFHcWw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_model = whisper.load_model(\"small\")\n"
      ],
      "metadata": {
        "id": "d0PfFA_bHeGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f148fa14-3eb9-4436-8da6-1dcd57efb872"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:12<00:00, 39.1MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a small Vosk English model if not present\n",
        "if not os.path.exists(\"vosk-model-small-en-us-0.15\"):\n",
        "    !wget -q https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "    !unzip -q vosk-model-small-en-us-0.15.zip\n",
        "\n",
        "vosk_model = Model(\"vosk-model-small-en-us-0.15\")\n"
      ],
      "metadata": {
        "id": "tYQDukPPHhkY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Groq client\n",
        "groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# Summarization function using Groq 'compound' model\n",
        "def summarize_with_groq(text):\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"groq/compound\",  # Model your key has access to\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional meeting summarizer. Summarize the transcript clearly and concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Meeting Transcript:\\n{text}\"}\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "8MjfT3Y0HtBk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Whisper transcription\n",
        "def transcribe_audio(file_path):\n",
        "    result = whisper_model.transcribe(file_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "# Vosk diarization\n",
        "def diarize_audio(file_path):\n",
        "    import wave\n",
        "    wf = wave.open(file_path, \"rb\")\n",
        "    rec = KaldiRecognizer(vosk_model, wf.getframerate())\n",
        "    segments = []\n",
        "    while True:\n",
        "        data = wf.readframes(4000)\n",
        "        if len(data) == 0:\n",
        "            break\n",
        "        if rec.AcceptWaveform(data):\n",
        "            res = json.loads(rec.Result())\n",
        "            if 'text' in res:\n",
        "                segments.append(res['text'])\n",
        "    final_res = json.loads(rec.FinalResult())\n",
        "    if 'text' in final_res:\n",
        "        segments.append(final_res['text'])\n",
        "    return segments\n",
        "\n",
        "# Summarization using Groq\n",
        "def summarize_text(text):\n",
        "    return summarize_with_groq(text)\n"
      ],
      "metadata": {
        "id": "VvavsRguHuf_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app_code = \"\"\"\\\n",
        "import streamlit as st\n",
        "import whisper\n",
        "from vosk import Model, KaldiRecognizer\n",
        "import wave\n",
        "import json\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    whisper_model = whisper.load_model(\"small\")\n",
        "    vosk_model = Model(\"vosk-model-small-en-us-0.15\")\n",
        "    groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "    return whisper_model, vosk_model, groq_client\n",
        "\n",
        "whisper_model, vosk_model, groq_client = load_models()\n",
        "\n",
        "st.title(\"Meeting Transcription + Diarization + Summarization (GroqAI)\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a meeting .wav file\", type=[\"wav\"])\n",
        "\n",
        "def summarize_with_groq(client, text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"groq/compound\",  # Accessible model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional meeting summarizer. Summarize the transcript clearly and concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Meeting Transcript:\\\\n{text}\"}\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    with open(\"temp.wav\", \"wb\") as f:\n",
        "        f.write(uploaded_file.read())\n",
        "\n",
        "    st.info(\"Transcribing...\")\n",
        "    transcription = whisper_model.transcribe(\"temp.wav\")[\"text\"]\n",
        "    st.success(\"Transcription complete!\")\n",
        "    st.text_area(\"Transcription\", transcription, height=200)\n",
        "\n",
        "    st.info(\"Performing diarization...\")\n",
        "    wf = wave.open(\"temp.wav\", \"rb\")\n",
        "    rec = KaldiRecognizer(vosk_model, wf.getframerate())\n",
        "    segments = []\n",
        "    while True:\n",
        "        data = wf.readframes(4000)\n",
        "        if len(data) == 0:\n",
        "            break\n",
        "        if rec.AcceptWaveform(data):\n",
        "            res = json.loads(rec.Result())\n",
        "            if 'text' in res:\n",
        "                segments.append(res['text'])\n",
        "    final_res = json.loads(rec.FinalResult())\n",
        "    if 'text' in final_res:\n",
        "        segments.append(final_res['text'])\n",
        "    st.success(\"Diarization complete!\")\n",
        "    st.text_area(\"Diarized Transcript\", \"\\\\n\".join(segments), height=200)\n",
        "\n",
        "    st.info(\"Summarizing with GroqAI...\")\n",
        "    summary = summarize_with_groq(groq_client, transcription)\n",
        "    st.success(\"Summary complete!\")\n",
        "    st.text_area(\"Meeting Summary\", summary, height=150)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/meeting_pipeline/app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n"
      ],
      "metadata": {
        "id": "oPUHIYT2HxrZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet\n"
      ],
      "metadata": {
        "id": "67eNnkOOHzvE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace with your own ngrok auth token\n",
        "ngrok.set_auth_token(\"33VBAydDytS0a0YnyvXwwzws4pr_5g5YRpRzom9RcK1STJNU9\")\n"
      ],
      "metadata": {
        "id": "ZsXcXCpAH1QV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5534282b-726d-42f1-e691-ff4ac23a8c15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Then start a new tunnel\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(\"Streamlit public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D3FVDofPHbT",
        "outputId": "ca2a3a59-71ff-4444-b969-850fac24d9c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: https://emboly-urgent-kristine.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/meeting_pipeline/app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8FkJE-i97SF",
        "outputId": "ef041cec-076b-43f0-8e17-ff2bff295917"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/meeting_pipeline/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit\n"
      ],
      "metadata": {
        "id": "zc9Egv2t-DbJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run /content/meeting_pipeline/app.py --server.port 8501 > /content/meeting_pipeline/streamlit.log 2>&1 &\n"
      ],
      "metadata": {
        "id": "UlOrO7QZ-FQ4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "time.sleep(10)  # Wait 10 seconds for the server to initialize\n"
      ],
      "metadata": {
        "id": "khrNwq7p-HFt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 20 /content/meeting_pipeline/streamlit.log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzZfAb7l-KTe",
        "outputId": "f406f8cb-a788-400c-c833-521967581965"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://34.16.199.99:8501\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any old tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start new tunnel on the port Streamlit is running\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(\"Streamlit public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "r8gG79YR-N9O",
        "outputId": "b301ed0d-7bab-43ac-d50b-74dd694a94c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: https://emboly-urgent-kristine.ngrok-free.dev\n"
          ]
        }
      ]
    }
  ]
}